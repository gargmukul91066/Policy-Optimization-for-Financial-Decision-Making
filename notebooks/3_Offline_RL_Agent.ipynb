{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c84464ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ⚙️ Install and Import Dependencies (Optional: d3rlpy)\n",
    "# !pip install d3rlpy\n",
    "\n",
    "import os, random, math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_auc_score, f1_score, confusion_matrix\n",
    "\n",
    "# Reproducibility\n",
    "RND = 42\n",
    "random.seed(RND)\n",
    "np.random.seed(RND)\n",
    "os.environ['PYTHONHASHSEED'] = str(RND)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7ba040cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes -> processed: (1803164, 42) | predictions: (270475, 2) | raw: (2260701, 151)\n"
     ]
    }
   ],
   "source": [
    "# Define File Paths and Verify Data Availability\n",
    "PROC_PATH = \"processed_loan_data.csv\"\n",
    "PROBS_PATH = \"test_predictions.csv\"\n",
    "RAW_PATH = \"accepted_2007_to_2018Q4.csv\"\n",
    "\n",
    "assert os.path.exists(PROC_PATH), f\"Missing {PROC_PATH}\"\n",
    "assert os.path.exists(PROBS_PATH), f\"Missing {PROBS_PATH}\"\n",
    "assert os.path.exists(RAW_PATH), f\"Missing {RAW_PATH}\"\n",
    "\n",
    "proc = pd.read_csv(PROC_PATH, low_memory=False)\n",
    "pred = pd.read_csv(PROBS_PATH, low_memory=False)\n",
    "raw = pd.read_csv(RAW_PATH, low_memory=False)\n",
    "\n",
    "print(\"Shapes -> processed:\", proc.shape, \"| predictions:\", pred.shape, \"| raw:\", raw.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f1fb6e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract Loan Amount and Interest Rate Columns\n",
    "if 'loan_amnt' in proc.columns and 'int_rate' in proc.columns:\n",
    "    loan_all = proc['loan_amnt'].values\n",
    "    rate_all = proc['int_rate'].values\n",
    "else:\n",
    "    raw_small = raw[['loan_amnt', 'int_rate', 'loan_status']].copy()\n",
    "    raw_small['int_rate'] = raw_small['int_rate'].astype(str).str.rstrip('%').replace('', np.nan).astype(float)\n",
    "    if raw_small['int_rate'].median() > 1:\n",
    "        raw_small['int_rate'] /= 100.0\n",
    "    loan_all = raw_small['loan_amnt'].values[:len(proc)]\n",
    "    rate_all = raw_small['int_rate'].values[:len(proc)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c9d577d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare Features and Target\n",
    "proc = proc.dropna(subset=['target'])\n",
    "X = proc.drop(columns=['target'], errors='ignore').values.astype(np.float32)\n",
    "y = proc['target'].astype(int).values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2fc38bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stratified Split with Index Tracking\n",
    "X_train, X_temp, y_train, y_temp, idx_train, idx_temp = train_test_split(\n",
    "    X, y, np.arange(len(y)), test_size=0.30, stratify=y, random_state=RND\n",
    ")\n",
    "X_val, X_test, y_val, y_test, idx_val, idx_test = train_test_split(\n",
    "    X_temp, y_temp, idx_temp, test_size=0.50, stratify=y_temp, random_state=RND\n",
    ")\n",
    "\n",
    "loan_train, rate_train = loan_all[idx_train], rate_all[idx_train]\n",
    "loan_val, rate_val = loan_all[idx_val], rate_all[idx_val]\n",
    "loan_test, rate_test = loan_all[idx_test], rate_all[idx_test]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c5f34062",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Reward Functions\n",
    "def realized_reward(action, loan_amt, int_rate, true_label):\n",
    "    if action == 0:\n",
    "        return 0.0\n",
    "    if true_label == 0:\n",
    "        return loan_amt * int_rate\n",
    "    return -loan_amt\n",
    "\n",
    "def expected_reward_from_p(p_default, loan_amt, int_rate):\n",
    "    return (1 - p_default) * (loan_amt * int_rate) - p_default * loan_amt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e3a82870",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load or Compute Default Probabilities\n",
    "if {'p_default', 'y_true'}.issubset(pred.columns):\n",
    "    p_test = pred['p_default'].values\n",
    "    y_test_saved = pred['y_true'].values\n",
    "else:\n",
    "    try:\n",
    "        import tensorflow as tf\n",
    "        model = tf.keras.models.load_model(\"keras_default_pred.h5\")\n",
    "        p_test = model.predict(X_test, batch_size=512).ravel()\n",
    "        y_test_saved = y_test\n",
    "    except Exception:\n",
    "        rf = RandomForestClassifier(n_estimators=200, max_depth=10, random_state=RND, n_jobs=-1)\n",
    "        rf.fit(X_train, y_train)\n",
    "        p_test = rf.predict_proba(X_test)[:, 1]\n",
    "        y_test_saved = y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6b1337ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute Expected Rewards and Build Test DataFrame\n",
    "n = len(p_test)\n",
    "loan_test_aligned = proc['loan_amnt'].iloc[:n].values\n",
    "rate_test_aligned = proc['int_rate'].iloc[:n].values\n",
    "\n",
    "exp_rew_test = expected_reward_from_p(p_test, loan_test_aligned, rate_test_aligned)\n",
    "df_test = pd.DataFrame({\n",
    "    'y_true': y_test_saved[:n],\n",
    "    'p_default': p_test,\n",
    "    'loan_amnt': loan_test_aligned,\n",
    "    'int_rate': rate_test_aligned,\n",
    "    'exp_reward': exp_rew_test\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c0faff1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top_80: selected 216380/270475 | avg expected reward = 0.34\n",
      "top_50: selected 135238/270475 | avg expected reward = 0.61\n",
      "top_19: selected 51391/270475 | avg expected reward = 1.07\n",
      "top_5: selected 13524/270475 | avg expected reward = 1.67\n"
     ]
    }
   ],
   "source": [
    "# Evaluate Static Quantile-Based Policies\n",
    "quantiles = {'top_80': 0.2, 'top_50': 0.5, 'top_19': 0.81, 'top_5': 0.95}\n",
    "for name, q in quantiles.items():\n",
    "    thr = df_test['exp_reward'].quantile(q)\n",
    "    selected = df_test[df_test['exp_reward'] >= thr]\n",
    "    print(f\"{name}: selected {len(selected)}/{len(df_test)} | avg expected reward = {selected['exp_reward'].mean():.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d5a1d5d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gym has been unmaintained since 2022 and does not support NumPy 2.0 amongst other critical functionality.\n",
      "Please upgrade to Gymnasium, the maintained drop-in replacement of Gym, or contact the authors of your software and request that they upgrade.\n",
      "Users of this version of Gym should be able to simply replace 'import gym' with 'import gymnasium as gym' in the vast majority of cases.\n",
      "See the migration guide at https://gymnasium.farama.org/introduction/migration_guide/ for additional information.\n"
     ]
    }
   ],
   "source": [
    "# Attempt to Import d3rlpy for Offline RL\n",
    "use_d3rlpy = False\n",
    "try:\n",
    "    import d3rlpy\n",
    "    from d3rlpy.dataset import MDPDataset\n",
    "    from d3rlpy.algos import CQL\n",
    "    use_d3rlpy = True\n",
    "except Exception as e:\n",
    "    print(\"d3rlpy unavailable or failed import:\", e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "016f3e4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-10-26 12:26.33 [info     ] Signatures have been automatically determined. action_signature=Signature(dtype=[dtype('float32')], shape=[(1,)]) observation_signature=Signature(dtype=[dtype('float32')], shape=[(41,)]) reward_signature=Signature(dtype=[dtype('float32')], shape=[(1,)])\n",
      "2025-10-26 12:26.33 [info     ] Action-space has been automatically determined. action_space=<ActionSpace.DISCRETE: 2>\n",
      "2025-10-26 12:26.36 [info     ] Action size has been automatically determined. action_size=2\n",
      "MDPDataset prepared with size: 941483\n"
     ]
    }
   ],
   "source": [
    "# Prepare MDPDataset for Offline RL (if d3rlpy Available)\n",
    "if use_d3rlpy:\n",
    "    obs = X_train.astype(np.float32)\n",
    "    acts = np.ones((len(obs), 1), dtype=np.float32)\n",
    "    rewards_train = np.array([realized_reward(1, la, r, t) for la, r, t in zip(loan_train, rate_train, y_train)], dtype=np.float32)\n",
    "    terminals = np.ones_like(rewards_train, dtype=bool)\n",
    "    mdp = MDPDataset(observations=obs, actions=acts, rewards=rewards_train, terminals=terminals)\n",
    "    print(\"MDPDataset prepared with size:\", len(obs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eb91728e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d3rlpy available. Preparing dataset for CQL.\n"
     ]
    }
   ],
   "source": [
    "use_d3rlpy = False\n",
    "try:\n",
    "    import d3rlpy\n",
    "    from d3rlpy.dataset import MDPDataset\n",
    "    from d3rlpy.algos import CQL\n",
    "    use_d3rlpy = True\n",
    "    print(\"d3rlpy available. Preparing dataset for CQL.\")\n",
    "except Exception as e:\n",
    "    print(\"d3rlpy unavailable or failed import:\", e)\n",
    "    use_d3rlpy = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "11d5ce74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-10-26 12:27.22 [info     ] dataset info                   dataset_info=DatasetInfo(observation_signature=Signature(dtype=[dtype('float32')], shape=[(41,)]), action_signature=Signature(dtype=[dtype('float32')], shape=[(1,)]), reward_signature=Signature(dtype=[dtype('float32')], shape=[(1,)]), action_space=<ActionSpace.DISCRETE: 2>, action_size=2)\n",
      "2025-10-26 12:27.22 [debug    ] Building models...            \n",
      "2025-10-26 12:27.24 [debug    ] Models have been built.       \n",
      "2025-10-26 12:27.24 [info     ] Directory is created at d3rlpy_logs\\DiscreteCQL_20251026122724\n",
      "2025-10-26 12:27.24 [info     ] Parameters                     params={'observation_shape': [41], 'action_size': 2, 'config': {'type': 'discrete_cql', 'params': {'batch_size': 256, 'gamma': 0.99, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0001, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 8000, 'alpha': 1.0}}}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf0384520c394a0facf0e87c0dedf357",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1/10:   0%|          | 0/5000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-10-26 12:29.40 [info     ] DiscreteCQL_20251026122724: epoch=1 step=5000 epoch=1 metrics={'time_sample_batch': 0.009399208784103394, 'time_algorithm_update': 0.017446479415893553, 'loss': nan, 'td_loss': nan, 'conservative_loss': nan, 'time_step': 0.0269882520198822} step=5000\n",
      "2025-10-26 12:29.40 [info     ] Model parameters are saved to d3rlpy_logs\\DiscreteCQL_20251026122724\\model_5000.d3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6ca8dd919de4b34ae0950d0079201c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2/10:   0%|          | 0/5000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-10-26 12:31.53 [info     ] DiscreteCQL_20251026122724: epoch=2 step=10000 epoch=2 metrics={'time_sample_batch': 0.009236612462997437, 'time_algorithm_update': 0.017077057695388795, 'loss': nan, 'td_loss': nan, 'conservative_loss': nan, 'time_step': 0.02646240816116333} step=10000\n",
      "2025-10-26 12:31.53 [info     ] Model parameters are saved to d3rlpy_logs\\DiscreteCQL_20251026122724\\model_10000.d3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b75e9d37ee04263b06aeb724114544c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3/10:   0%|          | 0/5000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-10-26 12:33.36 [info     ] DiscreteCQL_20251026122724: epoch=3 step=15000 epoch=3 metrics={'time_sample_batch': 0.006638333654403686, 'time_algorithm_update': 0.01369930419921875, 'loss': nan, 'td_loss': nan, 'conservative_loss': nan, 'time_step': 0.020479881858825683} step=15000\n",
      "2025-10-26 12:33.36 [info     ] Model parameters are saved to d3rlpy_logs\\DiscreteCQL_20251026122724\\model_15000.d3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "249f13efca0b41aca9847c58c85c2b81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 4/10:   0%|          | 0/5000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-10-26 12:35.40 [info     ] DiscreteCQL_20251026122724: epoch=4 step=20000 epoch=4 metrics={'time_sample_batch': 0.008498343276977538, 'time_algorithm_update': 0.01580895586013794, 'loss': nan, 'td_loss': nan, 'conservative_loss': nan, 'time_step': 0.024459044313430787} step=20000\n",
      "2025-10-26 12:35.40 [info     ] Model parameters are saved to d3rlpy_logs\\DiscreteCQL_20251026122724\\model_20000.d3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27ae3c5c44a7496cb7ea9dabc7832619",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 5/10:   0%|          | 0/5000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-10-26 12:38.46 [info     ] DiscreteCQL_20251026122724: epoch=5 step=25000 epoch=5 metrics={'time_sample_batch': 0.013325560283660888, 'time_algorithm_update': 0.023487577295303343, 'loss': nan, 'td_loss': nan, 'conservative_loss': nan, 'time_step': 0.03699236278533936} step=25000\n",
      "2025-10-26 12:38.46 [info     ] Model parameters are saved to d3rlpy_logs\\DiscreteCQL_20251026122724\\model_25000.d3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99045fd0d9d140a488e4a4d08a1392ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 6/10:   0%|          | 0/5000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-10-26 12:40.39 [info     ] DiscreteCQL_20251026122724: epoch=6 step=30000 epoch=6 metrics={'time_sample_batch': 0.007624328374862671, 'time_algorithm_update': 0.014611360883712768, 'loss': nan, 'td_loss': nan, 'conservative_loss': nan, 'time_step': 0.02235144238471985} step=30000\n",
      "2025-10-26 12:40.39 [info     ] Model parameters are saved to d3rlpy_logs\\DiscreteCQL_20251026122724\\model_30000.d3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b48055db8b8744979b0574f7b3e8bfdd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 7/10:   0%|          | 0/5000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-10-26 12:42.30 [info     ] DiscreteCQL_20251026122724: epoch=7 step=35000 epoch=7 metrics={'time_sample_batch': 0.007834521579742432, 'time_algorithm_update': 0.01415584478378296, 'loss': nan, 'td_loss': nan, 'conservative_loss': nan, 'time_step': 0.02209691252708435} step=35000\n",
      "2025-10-26 12:42.30 [info     ] Model parameters are saved to d3rlpy_logs\\DiscreteCQL_20251026122724\\model_35000.d3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e608279a7614ea5953945cd38dc0230",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 8/10:   0%|          | 0/5000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-10-26 12:43.59 [info     ] DiscreteCQL_20251026122724: epoch=8 step=40000 epoch=8 metrics={'time_sample_batch': 0.0059789172649383545, 'time_algorithm_update': 0.011572920513153076, 'loss': nan, 'td_loss': nan, 'conservative_loss': nan, 'time_step': 0.017669126129150392} step=40000\n",
      "2025-10-26 12:43.59 [info     ] Model parameters are saved to d3rlpy_logs\\DiscreteCQL_20251026122724\\model_40000.d3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4bfe7e988e264c819c2d3b7396f99cc6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 9/10:   0%|          | 0/5000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-10-26 12:45.22 [info     ] DiscreteCQL_20251026122724: epoch=9 step=45000 epoch=9 metrics={'time_sample_batch': 0.00590876669883728, 'time_algorithm_update': 0.010608326148986817, 'loss': nan, 'td_loss': nan, 'conservative_loss': nan, 'time_step': 0.016616143894195558} step=45000\n",
      "2025-10-26 12:45.22 [info     ] Model parameters are saved to d3rlpy_logs\\DiscreteCQL_20251026122724\\model_45000.d3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e383e522fdb042a5941b9401e54c1401",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 10/10:   0%|          | 0/5000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-10-26 12:47.42 [info     ] DiscreteCQL_20251026122724: epoch=10 step=50000 epoch=10 metrics={'time_sample_batch': 0.009921845865249634, 'time_algorithm_update': 0.017585837078094482, 'loss': nan, 'td_loss': nan, 'conservative_loss': nan, 'time_step': 0.02765393533706665} step=50000\n",
      "2025-10-26 12:47.42 [info     ] Model parameters are saved to d3rlpy_logs\\DiscreteCQL_20251026122724\\model_50000.d3\n",
      "✅ CQL model trained and saved.\n"
     ]
    }
   ],
   "source": [
    "# ⚙️ Configure and Train Discrete CQL Agent (d3rlpy ≥2.8.1)\n",
    "if use_d3rlpy:\n",
    "    import torch\n",
    "    from d3rlpy.algos import DiscreteCQL, DiscreteCQLConfig\n",
    "    from d3rlpy.models.encoders import DefaultEncoderFactory\n",
    "    from d3rlpy.models.q_functions import MeanQFunctionFactory\n",
    "\n",
    "    # Build factories and config\n",
    "    encoder_factory = DefaultEncoderFactory()\n",
    "    q_func_factory = MeanQFunctionFactory()\n",
    "    cql_config = DiscreteCQLConfig(\n",
    "        learning_rate=1e-4,\n",
    "        batch_size=256,\n",
    "        gamma=0.99,\n",
    "        encoder_factory=encoder_factory,\n",
    "        q_func_factory=q_func_factory,\n",
    "    )\n",
    "\n",
    "    # Instantiate agent (new signature requires enable_ddp)\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    enable_ddp = False\n",
    "    cql = DiscreteCQL(cql_config, device, enable_ddp)\n",
    "\n",
    "    # Train agent\n",
    "    cql.fit(dataset=mdp, n_steps=50000, n_steps_per_epoch=5000)\n",
    "\n",
    "    # Save model\n",
    "    os.makedirs(\"models\", exist_ok=True)\n",
    "    cql.save_model(\"models/discrete_cql_model\")\n",
    "    print(\"CQL model trained and saved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c8b687e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action distribution: {0: 201747}\n",
      "\n",
      "Predicted 201747 actions | Approvals: 0 (0.00%)\n"
     ]
    }
   ],
   "source": [
    "# 🔮 Predict Actions using Trained CQL Agent\n",
    "if use_d3rlpy:\n",
    "    obs_test = X_test.astype(np.float32)\n",
    "    cql_actions = np.array(cql.predict(obs_test)).astype(int).ravel()\n",
    "\n",
    "    unique, counts = np.unique(cql_actions, return_counts=True)\n",
    "    print(\"Action distribution:\", dict(zip(unique, counts)))\n",
    "\n",
    "    approvals = cql_actions.sum()\n",
    "    print(f\"\\nPredicted {len(cql_actions)} actions | Approvals: {approvals} ({100 * approvals / len(cql_actions):.2f}%)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ac905fc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
